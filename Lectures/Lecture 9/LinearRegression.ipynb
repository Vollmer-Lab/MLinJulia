{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"All models are wrong but some are useful\"\n",
    "> \\\\ \\\\\n",
    "> George Box (Box, 1976)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial begins with a very provocative quote from the statistician\n",
    "[George Box](https://en.wikipedia.org/wiki/George_E._P._Box) (figure below)\n",
    "on statistical models. Yes, all models are somehow wrong. But they are very useful.\n",
    "The idea is that the reality is too complex for us to understand when analyzing it in\n",
    "a naked and raw way. We need to somehow simplify it into individual components and analyze\n",
    "their relationships. But there is a danger here: any simplification of reality promotes loss\n",
    "of information in some way. Therefore, we always have a delicate balance between simplifications\n",
    "of reality through models and the inherent loss of information. Now you ask me:\n",
    "\"how are they useful?\" Imagine that you are in total darkness and you have a very powerful\n",
    "flashlight but with a narrow beam. Are you going to throw the flashlight away because it\n",
    "can't light everything around you and stay in the dark? You must use the flashlight to aim\n",
    "at interesting places in the darkness in order to illuminate them. You will never find a\n",
    "flashlight that illuminates everything with the clarity you need to analyze all the fine details\n",
    "of reality. Just as you will never find a unique model that will explain the whole reality around\n",
    "you. You need different flashlights just like you need different models. Without them you will\n",
    "be in total darkness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![George Box](../pages/images/george_box.jpg)\n",
    "\n",
    "\\center{*George Box*} \\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about a class of model known as linear regression. The idea here is to model a continuous dependent variable\n",
    "with a linear combination of independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathbf{y} = \\alpha +  \\mathbf{X} \\boldsymbol{\\beta} + \\epsilon \\label{linear reg} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\mathbf{y}$ -- dependent variable\n",
    "* $\\alpha$ -- intercept\n",
    "* $\\boldsymbol{\\beta}$ -- coefficient vector\n",
    "* $\\mathbf{X}$ -- data matrix\n",
    "* $\\epsilon$ -- model error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the $\\boldsymbol{\\beta}$ coefficients we use a Gaussian/normal likelihood function.\n",
    "Mathematically the Bayesian regression model is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{y} &\\sim \\text{Normal}\\left( \\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}, \\sigma \\right) \\\\\n",
    "\\alpha &\\sim \\text{Normal}(\\mu_\\alpha, \\sigma_\\alpha) \\\\\n",
    "\\boldsymbol{\\beta} &\\sim \\text{Normal}(\\mu_{\\boldsymbol{\\beta}}, \\sigma_{\\boldsymbol{\\beta}}) \\\\\n",
    "\\sigma &\\sim \\text{Exponential}(\\lambda_\\sigma)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the likelihood function $P(\\mathbf{y} \\mid \\boldsymbol{\\theta})$ is a normal distribution in which $\\mathbf{y}$\n",
    "depends on the parameters of the model $\\alpha$ and $\\boldsymbol{\\beta}$, in addition to having an\n",
    "error $\\sigma$. We condition $\\mathbf{y}$ onto the observed data $\\mathbf{X}$ by inserting\n",
    "$\\alpha + \\mathbf{X} \\cdot \\boldsymbol{\\beta}$ as the linear predictor of the model (the mean $\\mu$ parameter of the\n",
    "model's Normal likelihood function, and $\\sigma$ is the variance parameter). What remains is to specify which are the\n",
    "priors of the model parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prior Distribution of $\\alpha$ -- Knowledge we possess regarding the model's intercept.\n",
    "* Prior Distribution of $\\boldsymbol{\\beta}$  -- Knowledge we possess regarding the model's independent variables' coefficients.\n",
    "* Prior Distribution of $\\sigma$ -- Knowledge we possess regarding the model's error. Important that the error can only be positive. In addition, it is intuitive to place a distribution that gives greater weight to values close to zero, but that also allows values that are far from zero, so a distribution with a long tail is welcome. Candidate distributions are $\\text{Exponential}$ which is only supported on positive real numbers (so it solves the question of negative errors) or $\\text{Cauchy}^+$ truncated to only positive numbers (remembering that the distribution Cauchy is Student's $t$ with degrees of freedom $\\nu = 1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to instantiate a linear regression with the observed data ($\\mathbf{y}$ and $\\mathbf{X}$) and find the posterior\n",
    "distribution of our model's parameters of interest ($\\alpha$ and $\\boldsymbol{\\beta}$). This means to find the full posterior\n",
    "distribution of:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(\\boldsymbol{\\theta} \\mid \\mathbf{y}) = P(\\alpha, \\boldsymbol{\\beta}, \\sigma \\mid \\mathbf{y}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is easily accomplished with Turing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: [Turing]: progress logging is disabled globally\n",
      "└ @ Turing /Users/svollmer/.julia/packages/Turing/rl6ku/src/Turing.jl:22\n",
      "┌ Info: [AdvancedVI]: global PROGRESS is set as false\n",
      "└ @ AdvancedVI /Users/svollmer/.julia/packages/AdvancedVI/W2zsz/src/AdvancedVI.jl:15\n"
     ]
    }
   ],
   "source": [
    "using Turing\n",
    "using Statistics: mean, std\n",
    "using Random:seed!\n",
    "seed!(123)\n",
    "setprogress!(false) # hide\n",
    "\n",
    "@model function linreg(X, y; predictors=size(X, 2))\n",
    "    #priors\n",
    "    α ~ Normal(mean(y), 2.5 * std(y))\n",
    "    β ~ filldist(TDist(3), predictors)\n",
    "    σ ~ Exponential(1)\n",
    "\n",
    "    #likelihood\n",
    "    y ~ MvNormal(α .+ X * β, σ)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am specifying very weakly informative priors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\alpha \\sim \\text{Normal}(\\bar{\\mathbf{y}}, 2.5 \\cdot \\sigma_{\\mathbf{y}})$ -- This means a normal distribution centered on `y`'s mean with a standard deviation 2.5 times the standard deviation of `y`. That prior should with ease cover all possible values of $\\alpha$. Remember that the normal distribution has support over all the real number line $\\in (-\\infty, +\\infty)$.\n",
    "* $\\boldsymbol{\\beta} \\sim \\text{Student-}t(0,1,3)$ -- The predictors all have a prior distribution of a Student-$t$ distribution centered on 0 with variance 1 and degrees of freedom $\\nu = 3$. That wide-tailed $t$ distribution will cover all possible values for our coefficients. Remember the Student-$t$ also has support over all the real number line $\\in (-\\infty, +\\infty)$. Also the `filldist()` is a nice Turing's function which takes any univariate or multivariate distribution and returns another distribution that repeats the input distribution.\n",
    "* $\\sigma \\sim \\text{Exponential}(1)$ -- A wide-tailed-positive-only distribution perfectly suited for our model's error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - Children's IQ Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, I will use a famous dataset called `kidiq` (Gelman & Hill, 2007), which is data from a survey of adult American women and their respective children. Dated from 2007, it has 434 observations and 4 variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `kid_score`: child's IQ\n",
    "* `mom_hs`: binary/dummy (0 or 1) if the child's mother has a high school diploma\n",
    "* `mom_iq`: mother's IQ\n",
    "* `mom_age`: mother's age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's read our data with `CSV.jl` and output into a `DataFrame` from `DataFrames.jl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>4 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"Float64\">Float64</th><th title=\"Real\">Real</th><th title=\"Float64\">Float64</th><th title=\"Real\">Real</th><th title=\"Int64\">Int64</th><th title=\"DataType\">DataType</th></tr></thead><tbody><tr><th>1</th><td>kid_score</td><td>86.7972</td><td>20</td><td>90.0</td><td>144</td><td>0</td><td>Int64</td></tr><tr><th>2</th><td>mom_hs</td><td>0.785714</td><td>0</td><td>1.0</td><td>1</td><td>0</td><td>Int64</td></tr><tr><th>3</th><td>mom_iq</td><td>100.0</td><td>71.0374</td><td>97.9153</td><td>138.893</td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>mom_age</td><td>22.7857</td><td>17</td><td>23.0</td><td>29</td><td>0</td><td>Int64</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Real & Float64 & Real & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & kid\\_score & 86.7972 & 20 & 90.0 & 144 & 0 & Int64 \\\\\n",
       "\t2 & mom\\_hs & 0.785714 & 0 & 1.0 & 1 & 0 & Int64 \\\\\n",
       "\t3 & mom\\_iq & 100.0 & 71.0374 & 97.9153 & 138.893 & 0 & Float64 \\\\\n",
       "\t4 & mom\\_age & 22.7857 & 17 & 23.0 & 29 & 0 & Int64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m4×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable  \u001b[0m\u001b[1m mean       \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol    \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Real    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Real    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────────────\n",
       "   1 │ kid_score   86.7972    20       90.0     144             0  Int64\n",
       "   2 │ mom_hs       0.785714   0        1.0       1             0  Int64\n",
       "   3 │ mom_iq     100.0       71.0374  97.9153  138.893         0  Float64\n",
       "   4 │ mom_age     22.7857    17       23.0      29             0  Int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CSV, HTTP\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/storopoli/Bayesian-Julia/master/datasets/kidiq.csv\"\n",
    "kidiq = CSV.read(HTTP.get(url).body, DataFrame)\n",
    "describe(kidiq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the `describe()` output, the mean children's IQ is around 87 while the mother's is 100. Also the mother's\n",
    "range from 17 to 29 years with mean of around 23 years old. Finally, note that 79% of mothers have a high school diploma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's us instantiate our model with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Matrix(select(kidiq, Not(:kid_score)))\n",
    "y = kidiq[:, :kid_score]\n",
    "model = linreg(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, we will sample from the Turing model. We will be using the default `NUTS()` sampler with `2_000` samples, but\n",
    "now we will sample from 4 Markov chains using multiple threads `MCMCThreads()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Only a single thread available: MCMC chains are not sampled in parallel\n",
      "└ @ AbstractMCMC /Users/svollmer/.julia/packages/AbstractMCMC/6aLyN/src/sample.jl:292\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Info: Found initial step size\n",
      "│   ϵ = 0.0001953125\n",
      "└ @ Turing.Inference /Users/svollmer/.julia/packages/Turing/rl6ku/src/inference/hmc.jl:188\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Info: Found initial step size\n",
      "│   ϵ = 0.00078125\n",
      "└ @ Turing.Inference /Users/svollmer/.julia/packages/Turing/rl6ku/src/inference/hmc.jl:188\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Info: Found initial step size\n",
      "│   ϵ = 9.765625e-5\n",
      "└ @ Turing.Inference /Users/svollmer/.julia/packages/Turing/rl6ku/src/inference/hmc.jl:188\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Warning: The current proposal will be rejected due to numerical error(s).\n",
      "│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n",
      "└ @ AdvancedHMC /Users/svollmer/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n",
      "┌ Info: Found initial step size\n",
      "│   ϵ = 0.0001953125\n",
      "└ @ Turing.Inference /Users/svollmer/.julia/packages/Turing/rl6ku/src/inference/hmc.jl:188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Summary Statistics\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m naive_se \u001b[0m \u001b[1m    mcse \u001b[0m \u001b[1m       ess \u001b[0m \u001b[1m    rhat \u001b[0m \u001b[1m \u001b[0m ⋯\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m   Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m \u001b[0m ⋯\n",
       "\n",
       "           α   21.7916    8.6786     0.0970    0.1603   3008.1551    1.0003    ⋯\n",
       "        β[1]    2.0599    1.8433     0.0206    0.0332   3301.1969    1.0000    ⋯\n",
       "        β[2]    0.5788    0.0591     0.0007    0.0010   3900.4648    1.0000    ⋯\n",
       "        β[3]    0.2424    0.3105     0.0035    0.0050   3820.6865    1.0001    ⋯\n",
       "           σ   17.8869    0.5788     0.0065    0.0082   6242.3403    1.0001    ⋯\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = sample(model, NUTS(), MCMCThreads(), 2_000, 4)\n",
    "summarystats(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had no problem with the Markov chains as all the `rhat` are well below `1.01` (or above `0.99`).\n",
    "Our model has an error `σ` of around 18. So it estimates IQ±9. The intercept `α` is the basal child's IQ.\n",
    "So each child has 22±9 IQ before we add the coefficients multiplied by the child's independent variables.\n",
    "And from our coefficients $\\boldsymbol{\\beta}$, we can see that the `quantile()` tells us the uncertainty around their\n",
    "estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantiles\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m   97.5% \u001b[0m\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
       "\n",
       "           α    4.7276   16.0186   21.7499   27.5061   38.8603\n",
       "        β[1]   -0.6403    0.7240    1.7129    3.0420    6.4122\n",
       "        β[2]    0.4628    0.5390    0.5795    0.6190    0.6942\n",
       "        β[3]   -0.3623    0.0344    0.2465    0.4497    0.8646\n",
       "           σ   16.7971   17.5026   17.8695   18.2615   19.0667\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `β[1]` -- first column of `X`, `mom_hs`, has 95% credible interval that is all over the place, including zero. So its effect on child's IQ is inconclusive.\n",
    "* `β[2]` -- second column of `X`, `mom_iq`, has a 95% credible interval from 0.46 to 0.69. So we expect that every increase in the mother's IQ is associated with a 0.46 to 0.69 increase in the child's IQ.\n",
    "* `β[3]` -- third column of `X`, `mom_age`, has also 95% credible interval that is all over the place, including zero. Like `mom_hs`, its effect on child's IQ is inconclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how you interpret 95% credible intervals from a `quantile()` output of a linear regression `Chains` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box, G. E. P. (1976). Science and Statistics. Journal of the American Statistical Association, 71(356), 791–799. https://doi.org/10.2307/2286841\n",
    "\n",
    "Gelman, A., & Hill, J. (2007). Data analysis using regression and multilevel/hierarchical models. Cambridge university press."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
